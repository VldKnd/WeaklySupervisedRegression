{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76bf5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data import *\n",
    "from src.utils import *\n",
    "from src.main import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "from numpy import real\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.utils.extmath import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213a0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"beta\":0.001,\n",
    "    \"gamma\":0.001,\n",
    "    \"n_clusters\":50,\n",
    "    \"n_models\":2,\n",
    "    \"verbose\":True,\n",
    "    \"train_size\": 0.01,\n",
    "    \"weak_size\": 0.1,\n",
    "    \"test_size\": 0.89,\n",
    "    \"random_state\":42,\n",
    "    \"path\":\"./data/pp_gas_emission/\",\n",
    "    \"y\":[\"CO\", \"NOX\"],\n",
    "    \"rank\":100,\n",
    "}\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9ec079",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2015 = pd.read_csv(cfg[\"path\"]+\"gt_2015.csv\")\n",
    "X_data_2015 = data_2015.drop(cfg[\"y\"], axis=1).to_numpy()\n",
    "y_data_2015 = data_2015[cfg[\"y\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9cb8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_weak = cfg[\"weak_size\"]/(cfg[\"train_size\"] + cfg[\"weak_size\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data_2015, y_data_2015,\n",
    "                                                    test_size=cfg[\"test_size\"], random_state=cfg[\"random_state\"])\n",
    "X_train, X_weak, y_train, y_weak = train_test_split(X_train, y_train,\n",
    "                                                    test_size=size_weak, random_state=cfg[\"random_state\"])\n",
    "\n",
    "X_all = np.concatenate([X_train, X_weak, X_test])\n",
    "y_all = np.concatenate([y_train, y_weak, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69647840",
   "metadata": {},
   "source": [
    "### Regression experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f0eee8",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25490c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train L2 39.89840\n",
      "Test L2 56.09307\n",
      "Test L2 57.60034\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print(\"Train L2 {:.5f}\".format((np.linalg.norm(y_train - reg.predict(X_train), axis=1)**2).mean()))\n",
    "print(\"Test L2 {:.5f}\".format((np.linalg.norm(y_weak - reg.predict(X_weak), axis=1)**2).mean()))\n",
    "print(\"Test L2 {:.5f}\".format((np.linalg.norm(y_test - reg.predict(X_test), axis=1)**2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760c059",
   "metadata": {},
   "source": [
    "#### Co-assosiation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a95c2bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 KMeans models: 1 2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 7384/7384 [00:00<00:00, 9576.40it/s]\n"
     ]
    }
   ],
   "source": [
    "ScaleX = MinMaxScaler()\n",
    "X_all_scaled = ScaleX.fit_transform(X_all)\n",
    "W = get_W_k_means(X_all_scaled, \n",
    "                  n_clusters=cfg[\"n_clusters\"],\n",
    "                  n_models=cfg[\"n_models\"],\n",
    "                  verbose=cfg[\"verbose\"])\n",
    "\n",
    "\n",
    "neigh_100 = W.argsort()[:, -100:][:, ::-1]\n",
    "L = []\n",
    "for i in (pbar := tqdm(range(neigh_100.shape[0]))):\n",
    "    #neigh_20 = np.argpartition((y_all[neigh_100[i]]**2).sum(axis=1), 20)[:20]\n",
    "    cov = np.cov(y_all[neigh_100[i]], rowvar=False)\n",
    "    try:\n",
    "        L_i = np.linalg.cholesky(cov)\n",
    "        L_idx = np.tril_indices_from(L_i)\n",
    "        L.append(L_i[L_idx])\n",
    "    except LinAlgError:\n",
    "        print(\"Cholesky Failed\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093b3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_all = np.stack(L)\n",
    "A_all = y_all\n",
    "\n",
    "L_train = L_all[:X_train.shape[0]]\n",
    "A_train = A_all[:X_train.shape[0]]\n",
    "L_weak = L_all[X_train.shape[0]:X_train.shape[0]+X_weak.shape[0]]\n",
    "A_weak = A_all[X_train.shape[0]:X_train.shape[0]+X_weak.shape[0]]\n",
    "L_test = L_all[X_train.shape[0]+X_weak.shape[0]:]\n",
    "A_test = A_all[X_train.shape[0]+X_weak.shape[0]:]\n",
    "\n",
    "X_full = np.concatenate([X_train, X_weak, X_test])\n",
    "Y_full = np.concatenate([y_train, y_weak, np.zeros_like(y_test)])\n",
    "L_full = np.concatenate([L_train, L_weak, np.zeros_like(L_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667e5f6",
   "metadata": {},
   "source": [
    "#### Correlated WSR-LRCM\n",
    "Weakly Supervised Regression Lower Rank Co-assosiation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "156adc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_full = np.diag(np.concatenate([\n",
    "    np.ones(X_train.shape[0]+X_weak.shape[0])*cfg[\"beta\"] + 1,\n",
    "    np.ones(X_test.shape[0])*cfg[\"beta\"]]))\n",
    "\n",
    "A_star, L_star = solve(W, B_full, Y_full, L_full, gamma=cfg[\"gamma\"])\n",
    "\n",
    "A_star_gt_train = A_star[:X_train.shape[0]]\n",
    "L_star_gt_train = L_star[:X_train.shape[0]]\n",
    "\n",
    "A_star_gt_weak = A_star[X_train.shape[0]:X_train.shape[0]+X_weak.shape[0]]\n",
    "L_star_gt_weak = L_star[X_train.shape[0]:X_train.shape[0]+X_weak.shape[0]]\n",
    "\n",
    "A_star_gt_test = A_star[X_train.shape[0]+X_weak.shape[0]:]\n",
    "L_star_gt_test = L_star[X_train.shape[0]+X_weak.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c47f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2\n",
      "Train L2 1.80473\n",
      "Weak L2 2.26503\n",
      "Test L2 48.56968\n",
      "\n",
      "MWD\n",
      "Train L2 1.93929\n",
      "Weak L2 2.34095\n",
      "Test L2 50.63598\n"
     ]
    }
   ],
   "source": [
    "print(\"L2\")\n",
    "print(\"Train L2 {:.5f}\".format((np.linalg.norm(A_train - A_star_gt_train, axis=1)**2).mean()))\n",
    "print(\"Weak L2 {:.5f}\".format((np.linalg.norm(A_weak - A_star_gt_weak, axis=1)**2).mean()))\n",
    "print(\"Test L2 {:.5f}\".format((np.linalg.norm(A_test - A_star_gt_test, axis=1)**2).mean()), end=\"\\n\\n\")\n",
    "\n",
    "print(\"MWD\")\n",
    "print(\"Train L2 {:.5f}\".format(get_Wasserstain(A_train, L_train, A_star_gt_train, L_star_gt_train)))\n",
    "print(\"Weak L2 {:.5f}\".format(get_Wasserstain(A_weak, L_weak, A_star_gt_weak, L_star_gt_weak)))\n",
    "print(\"Test L2 {:.5f}\".format(get_Wasserstain(A_test, L_test, A_star_gt_test, L_star_gt_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc02c3b",
   "metadata": {},
   "source": [
    "#### WSR-LRCM\n",
    "Correlated Weakly Supervised Regression Lower Rank Co-assosiation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d06c509e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2\n",
      "Train L2 1.80473\n",
      "Weak L2 2.26503\n",
      "Test L2 48.56968\n",
      "\n",
      "MWD\n",
      "Train L2 12.94202\n",
      "Weak L2 10.35490\n",
      "Test L2 58.12554\n"
     ]
    }
   ],
   "source": [
    "L_star[:, 1] = 0\n",
    "\n",
    "print(\"L2\")\n",
    "print(\"Train L2 {:.5f}\".format((np.linalg.norm(A_train - A_star_gt_train, axis=1)**2).mean()))\n",
    "print(\"Weak L2 {:.5f}\".format((np.linalg.norm(A_weak - A_star_gt_weak, axis=1)**2).mean()))\n",
    "print(\"Test L2 {:.5f}\".format((np.linalg.norm(A_test - A_star_gt_test, axis=1)**2).mean()), end=\"\\n\\n\")\n",
    "\n",
    "print(\"MWD\")\n",
    "print(\"Train L2 {:.5f}\".format(get_Wasserstain(A_train, L_train, A_star_gt_train, L_star_gt_train)))\n",
    "print(\"Weak L2 {:.5f}\".format(get_Wasserstain(A_weak, L_weak, A_star_gt_weak, L_star_gt_weak)))\n",
    "print(\"Test L2 {:.5f}\".format(get_Wasserstain(A_test, L_test, A_star_gt_test, L_star_gt_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6eda9",
   "metadata": {},
   "source": [
    "### Low Rank Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1b0b7",
   "metadata": {},
   "source": [
    "#### Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e00e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2\n",
      "Train L2 1.80473\n",
      "Weak L2 2.26503\n",
      "Test L2 48.56968\n",
      "\n",
      "MWD\n",
      "Train L2 1.93929\n",
      "Weak L2 2.34095\n",
      "Test L2 50.63598\n"
     ]
    }
   ],
   "source": [
    "u, s, vt = svds(W, k=cfg[\"rank\"])\n",
    "C_1_T_svd, C_2_T_svd = u, np.diag(s)@vt\n",
    "D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "A_star, L_star = solve_sparse(D, C_1_T_svd, C_2_T_svd, B_full, Y_full, L_full, gamma=cfg[\"gamma\"])\n",
    "\n",
    "A_star_T_train = A_star[:X_train.shape[0]]\n",
    "L_star_T_train = L_star[:X_train.shape[0]]\n",
    "\n",
    "A_star_T_weak = A_star[X_train.shape[0]:X_train.shape[0]+X_weak.shape[0]]\n",
    "L_star_T_weak = L_star[X_train.shape[0]:X_train.shape[0]+X_weak.shape[0]]\n",
    "\n",
    "A_star_T_test = A_star[X_train.shape[0]+X_weak.shape[0]:]\n",
    "L_star_T_test = L_star[X_train.shape[0]+X_weak.shape[0]:]\n",
    "\n",
    "get_statistics(A_train, L_train, A_star_T_train, L_star_T_train,\n",
    "               A_weak, L_weak, A_star_T_weak, L_star_T_weak,\n",
    "               A_test, L_test, A_star_T_test, L_star_T_test,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f95c99",
   "metadata": {},
   "source": [
    "#### Random SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "755a3964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2\n",
      "Train L2 1.80473\n",
      "Weak L2 2.26503\n",
      "Test L2 48.56968\n",
      "\n",
      "MWD\n",
      "Train L2 1.93929\n",
      "Weak L2 2.34095\n",
      "Test L2 50.63598\n"
     ]
    }
   ],
   "source": [
    "u, s, vt = randomized_svd(W, n_components=cfg[\"rank\"], random_state=cfg[\"random_state\"])\n",
    "C_1_R_svd, C_2_R_svd = u, np.diag(s)@vt\n",
    "D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "A_star, L_star = solve_sparse(D, C_1_R_svd, C_2_R_svd, B_full, Y_full, L_full, gamma=cfg[\"gamma\"])\n",
    "\n",
    "A_star_R_train = A_star[:X_train.shape[0]]\n",
    "L_star_R_train = L_star[:X_train.shape[0]]\n",
    "\n",
    "A_star_R_weak = A_star[X_train.shape[0]:X_train.shape[0]+X_weak.shape[0]]\n",
    "L_star_R_weak = L_star[X_train.shape[0]:X_train.shape[0]+X_weak.shape[0]]\n",
    "\n",
    "A_star_R_test = A_star[X_train.shape[0]+X_weak.shape[0]:]\n",
    "L_star_R_test = L_star[X_train.shape[0]+X_weak.shape[0]:]\n",
    "\n",
    "get_statistics(A_train, L_train, A_star_R_train, L_star_R_train,\n",
    "               A_weak, L_weak, A_star_R_weak, L_star_R_weak,\n",
    "               A_test, L_test, A_star_R_test, L_star_R_test,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b367617",
   "metadata": {},
   "source": [
    "#### Nystrom Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8862921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2\n",
      "Train L2 11.82160\n",
      "Weak L2 21.08466\n",
      "Test L2 603.86608\n",
      "\n",
      "MWD\n",
      "Train L2 12.02805\n",
      "Weak L2 21.36203\n",
      "Test L2 612.38094\n"
     ]
    }
   ],
   "source": [
    "nystrom = Nystrom(cfg[\"rank\"])\n",
    "C_1_N, C_2_N = nystrom(W)\n",
    "D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "A_star, L_star = solve_sparse(D, C_1_N, C_2_N, B_full, Y_full, L_full, gamma=cfg[\"gamma\"])\n",
    "\n",
    "A_star_N_train = A_star[:X_train.shape[0]]\n",
    "L_star_N_train = L_star[:X_train.shape[0]]\n",
    "\n",
    "A_star_N_weak = A_star[X_train.shape[0]:X_train.shape[0]+X_weak.shape[0]]\n",
    "L_star_N_weak = L_star[X_train.shape[0]:X_train.shape[0]+X_weak.shape[0]]\n",
    "\n",
    "A_star_N_test = A_star[X_train.shape[0]+X_weak.shape[0]:]\n",
    "L_star_N_test = L_star[X_train.shape[0]+X_weak.shape[0]:]\n",
    "\n",
    "get_statistics(A_train, L_train, A_star_N_train, L_star_N_train,\n",
    "               A_weak, L_weak, A_star_N_weak, L_star_N_weak,\n",
    "               A_test, L_test, A_star_N_test, L_star_N_test,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
