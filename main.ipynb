{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from src.data import *\n",
    "from src.utils import *\n",
    "from src.main import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import k_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_weak = {\n",
    "    \"normalize\":False,\n",
    "    \"size\":1000,\n",
    "    \"weak_size\":0.3,\n",
    "    \"beta\":0.01,\n",
    "    \"gamma\":0.01,\n",
    "    \"n_features\":10,\n",
    "    \"n_clusters\":3,\n",
    "    \"n_components_x\":3,\n",
    "    \"n_components_y\":4,\n",
    "    \"n_outputs_y\":4,\n",
    "    \"noise_level_y\":0.6,\n",
    "    \"repetitions\":30,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 1.856, Mean Weak 19.123: 100%|███████| 30/30 [00:02<00:00, 11.84it/s]\n"
     ]
    }
   ],
   "source": [
    "tests_gaussian_singleoutput = {\n",
    "    \"weak\":[],\n",
    "    \"train\":[],\n",
    "}\n",
    "\n",
    "idxes_L_diag = []\n",
    "k = 0\n",
    "for i in range(2, cfg_weak[\"n_outputs_y\"]+2):\n",
    "    idxes_L_diag.append(k)\n",
    "    k+=i\n",
    "    \n",
    "dictionary = tests_gaussian_singleoutput\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_gaussian(X_full, normalize_W=cfg_weak[\"normalize\"])\n",
    "\n",
    "    L_full = L_full[:, idxes_L_diag]\n",
    "    A_star, L_star = solve(W, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "\n",
    "    L_star_single_weak = np.zeros_like(L_weak)\n",
    "    L_star_single_weak[:, idxes_L_diag] = L_star_weak\n",
    "    L_star_single_train = np.zeros_like(L_train)\n",
    "    L_star_single_train[:, idxes_L_diag] = L_star_train\n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_single_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_single_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))  \n",
    "    \n",
    "tests_gaussian_singleoutput = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 0.764, Mean Weak 0.752: 100%|████████| 30/30 [00:04<00:00,  6.54it/s]\n"
     ]
    }
   ],
   "source": [
    "tests_kmeans_singleoutput = {\n",
    "    \"weak\":[],\n",
    "    \"train\":[],\n",
    "}\n",
    "\n",
    "idxes_L_diag = []\n",
    "k = 0\n",
    "for i in range(2, cfg_weak[\"n_outputs_y\"]+2):\n",
    "    idxes_L_diag.append(k)\n",
    "    k+=i\n",
    "    \n",
    "dictionary = tests_kmeans_singleoutput\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_k_means(X_full, n_clusters=cfg_weak[\"n_clusters\"], normalize_W=cfg_weak[\"normalize\"])\n",
    "\n",
    "    L_full = L_full[:, idxes_L_diag]\n",
    "    A_star, L_star = solve(W, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "\n",
    "    L_star_single_weak = np.zeros_like(L_weak)\n",
    "    L_star_single_weak[:, idxes_L_diag] = L_star_weak\n",
    "    L_star_single_train = np.zeros_like(L_train)\n",
    "    L_star_single_train[:, idxes_L_diag] = L_star_train\n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_single_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_single_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))  \n",
    "    \n",
    "tests_kmeans_singleoutput = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 0.125, Mean Weak 0.136: 100%|████████| 30/30 [00:04<00:00,  6.46it/s]\n"
     ]
    }
   ],
   "source": [
    "tests_kmeans_multioutput = {\n",
    "    \"weak\":[],\n",
    "    \"train\":[],\n",
    "}\n",
    "\n",
    "dictionary = tests_kmeans_multioutput\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_k_means(X_full, n_clusters=cfg_weak[\"n_clusters\"], normalize_W=cfg_weak[\"normalize\"])\n",
    "    \n",
    "    A_star, L_star = solve(W, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "    \n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))\n",
    "    \n",
    "tests_kmeans_multioutput = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 1.156, Mean Weak 18.758: 100%|███████| 30/30 [00:02<00:00, 12.33it/s]\n"
     ]
    }
   ],
   "source": [
    "tests_gaussian_multioutput = {\n",
    "        \"weak\":[],\n",
    "        \"train\":[],\n",
    "    }\n",
    "\n",
    "dictionary = tests_gaussian_multioutput\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_gaussian(X_full, normalize_W=cfg_weak[\"normalize\"])\n",
    "    \n",
    "    A_star, L_star = solve(W, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "    \n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))\n",
    "    \n",
    "tests_gaussian_multioutput = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.suptitle('Wassestain distance\\nResults after 50 random simulations')\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.set_title(\"X_1\")\n",
    "ax1.boxplot([x[\"train\"] for x in [tests_kmeans_singleoutput, tests_gaussian_singleoutput, tests_kmeans_multioutput, tests_gaussian_multioutput]],\n",
    "           labels=[\"Not correalted\\nKmeans Clustering \\n3 clusters\", \"Not correalted\\nGaussian\", \"Kmeans Clustering\\n3 clusters\", \"Gaussian\"])\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.set_title(\"X_0\")\n",
    "ax2.boxplot([x[\"weak\"] for x in [tests_kmeans_singleoutput, tests_gaussian_singleoutput, tests_kmeans_multioutput, tests_gaussian_multioutput]],\n",
    "           labels=[\"Not correalted\\nKmeans Clustering \\n3 clusters\", \"Not correalted\\nGaussian\", \"Kmeans Clustering\\n3 clusters\", \"Gaussian\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 0.126, Mean Weak 0.139: 100%|████████| 30/30 [00:04<00:00,  6.37it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\n",
    "        \"weak\":[],\n",
    "        \"train\":[],\n",
    "    }\n",
    "\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_k_means(X_full, n_clusters=cfg_weak[\"n_clusters\"], normalize_W=cfg_weak[\"normalize\"])\n",
    "    \n",
    "    A_star, L_star = solve(W, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "    \n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))\n",
    "    \n",
    "tests_kmeans_gt = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 0.122, Mean Weak 0.133: 100%|████████| 30/30 [00:06<00:00,  4.35it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\n",
    "        \"weak\":[],\n",
    "        \"train\":[],\n",
    "    }\n",
    "rank = 50\n",
    "\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_k_means(X_full, n_clusters=cfg_weak[\"n_clusters\"], normalize_W=cfg_weak[\"normalize\"])\n",
    "    \n",
    "    u, s, vt = scipy.sparse.linalg.svds(W, k=rank)\n",
    "    C_1, C_2 = u, np.diag(s)@vt\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "    A_star, L_star = solve_sparse(D, C_1, C_2, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "    \n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))\n",
    "    \n",
    "tests_kmeans_svd = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 2.189, Mean Weak 2.889: 100%|████████| 30/30 [00:04<00:00,  6.90it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\n",
    "        \"weak\":[],\n",
    "        \"train\":[],\n",
    "    }\n",
    "rank = 50\n",
    "nystrom = Nystrom(rank)\n",
    "\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_k_means(X_full, n_clusters=cfg_weak[\"n_clusters\"], normalize_W=cfg_weak[\"normalize\"])\n",
    "    \n",
    "    C_1_N, C_2_N = nystrom(W)\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "    A_star, L_star = solve_sparse(D, C_1, C_2, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "    \n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))\n",
    "    \n",
    "tests_kmeans_nystrom = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 0.117, Mean Weak 0.128: 100%|████████| 30/30 [00:05<00:00,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\n",
    "        \"weak\":[],\n",
    "        \"train\":[],\n",
    "    }\n",
    "rank = 50\n",
    "\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_k_means(X_full, n_clusters=cfg_weak[\"n_clusters\"], normalize_W=cfg_weak[\"normalize\"])\n",
    "    u, s, vt = randomized_svd(W, n_components=rank, random_state=42)\n",
    "    C_1, C_2 = u, np.diag(s)@vt\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "    A_star, L_star = solve_sparse(D, C_1, C_2, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "    \n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))\n",
    "    \n",
    "tests_kmeans_random_svd = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 1.179, Mean Weak 18.906: 100%|███████| 30/30 [00:02<00:00, 11.37it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\n",
    "        \"weak\":[],\n",
    "        \"train\":[],\n",
    "    }\n",
    "\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_gaussian(X_full, normalize_W=cfg_weak[\"normalize\"])\n",
    "    \n",
    "    A_star, L_star = solve(W, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "    \n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))\n",
    "    \n",
    "tests_gauss_gt = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 1.140, Mean Weak 16.265: 100%|███████| 30/30 [00:12<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\n",
    "        \"weak\":[],\n",
    "        \"train\":[],\n",
    "    }\n",
    "rank = 50\n",
    "\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_gaussian(X_full, normalize_W=cfg_weak[\"normalize\"])\n",
    "    \n",
    "    u, s, vt = scipy.sparse.linalg.svds(W, k=rank)\n",
    "    C_1, C_2 = u, np.diag(s)@vt\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "    A_star, L_star = solve_sparse(D, C_1, C_2, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "    \n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))\n",
    "    \n",
    "tests_gauss_svd = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 1.178, Mean Weak 16.277: 100%|███████| 30/30 [00:02<00:00, 11.84it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\n",
    "        \"weak\":[],\n",
    "        \"train\":[],\n",
    "    }\n",
    "rank = 50\n",
    "nystrom = Nystrom(rank)\n",
    "\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_gaussian(X_full, normalize_W=cfg_weak[\"normalize\"])\n",
    "    \n",
    "    C_1_N, C_2_N = nystrom(W)\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "    A_star, L_star = solve_sparse(D, C_1, C_2, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "    \n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))\n",
    "    \n",
    "tests_gauss_nystrom = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Train 1.177, Mean Weak 19.079: 100%|███████| 30/30 [00:06<00:00,  4.98it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\n",
    "        \"weak\":[],\n",
    "        \"train\":[],\n",
    "    }\n",
    "rank = 50\n",
    "\n",
    "for i in (pbar := tqdm(range(cfg_weak[\"repetitions\"]))):\n",
    "    means = np.concatenate([\n",
    "                np.arange(cfg_weak[\"n_features\"])[None, :] + 8*i\n",
    "                for i in range(cfg_weak[\"n_components_x\"])\n",
    "            ])\n",
    "\n",
    "    X, Y, A, L = make_monte_carlo(means,\n",
    "                                  componenets_y=cfg_weak[\"n_components_y\"],\n",
    "                                  n_y=cfg_weak[\"n_outputs_y\"],\n",
    "                                  y_noise_level=cfg_weak[\"noise_level_y\"]\n",
    "                                 )\n",
    "    X_train, X_weak, Y_train, Y_weak, A_train, A_weak, L_train, L_weak = train_test_split(X, Y, A, L, test_size=cfg_weak[\"weak_size\"])\n",
    "    X_full = np.concatenate([X_train, X_weak])\n",
    "    Y_full = np.concatenate([Y_train, np.zeros_like(Y_weak)])\n",
    "    A_full = np.concatenate([A_train, np.zeros_like(A_weak)])\n",
    "    L_full = np.concatenate([L_train, np.zeros_like(L_weak)])\n",
    "    B_full = np.diag(np.concatenate([np.ones(X_train.shape[0])*cfg_weak[\"beta\"] + 1, np.ones(X_weak.shape[0])*cfg_weak[\"beta\"]]))\n",
    "    W = get_W_gaussian(X_full, normalize_W=cfg_weak[\"normalize\"])\n",
    "    \n",
    "    u, s, vt = randomized_svd(W, n_components=rank, random_state=42)\n",
    "    C_1, C_2 = u, np.diag(s)@vt\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "    A_star, L_star = solve_sparse(D, C_1, C_2, B_full, Y_full, L_full)\n",
    "    A_star_train, A_star_weak = A_star[:X_train.shape[0]], A_star[X_train.shape[0]:]\n",
    "    L_star_train, L_star_weak = L_star[:X_train.shape[0]], L_star[X_train.shape[0]:]\n",
    "    \n",
    "    dictionary[\"weak\"].append(get_Wasserstain(A_weak, L_weak, A_star_weak, L_star_weak))\n",
    "    dictionary[\"train\"].append(get_Wasserstain(A_train, L_train, A_star_train, L_star_train))\n",
    "    pbar.set_description(\"Mean Train {:.3f}, Mean Weak {:.3f}\".format(\n",
    "        sum(dictionary[\"train\"])/len(dictionary[\"train\"]),\n",
    "        sum(dictionary[\"weak\"])/len(dictionary[\"weak\"]),\n",
    "    ))\n",
    "    \n",
    "tests_gauss_random_svd = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dicts = [\n",
    "    tests_kmeans_gt,\n",
    "    tests_kmeans_svd,\n",
    "    tests_kmeans_nystrom,\n",
    "    tests_kmeans_random_svd,\n",
    "    tests_gauss_gt,\n",
    "    tests_gauss_svd,\n",
    "    tests_gauss_nystrom,\n",
    "    tests_gauss_random_svd,\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"Ground\\nTruth\",\n",
    "    \"Truncated\\nSVD\",\n",
    "    \"Nystrom\\nApproximation\",\n",
    "    \"Random\\nSVD\",\n",
    "    \"Ground\\nTruth\",\n",
    "    \"Truncated\\nSVD\",\n",
    "    \"Nystrom\\nApproximation\",\n",
    "    \"Random\\nSVD\",\n",
    "]\n",
    "\n",
    "suptitle = 'Result with {} components'.format(rank)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.suptitle(suptitle)\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.set_title(\"X_1\")\n",
    "ax1.boxplot([x[\"train\"] for x in dicts],\n",
    "           labels=names)\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.set_title(\"X_0\")\n",
    "ax2.boxplot([x[\"weak\"] for x in dicts],\n",
    "           labels=names)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
